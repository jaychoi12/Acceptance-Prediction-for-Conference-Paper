{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('test.tsv', delimiter='\\t')\n",
    "df2 = pd.read_csv('train.tsv', delimiter='\\t')\n",
    "df3 = pd.read_csv('dev.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01</th>\n",
       "      <th>Neural language models have been widely used in various NLP tasks, including machine translation, next word prediction and conversational agents. However, it is challenging to deploy these models on mobile devices due to their slow prediction speed, where the bottleneck is to compute top candidates in the softmax layer. In this paper, we introduce a novel softmax layer approximation algorithm by exploiting the clustering structure of context vectors. Our algorithm uses a light-weight screening model to predict a much smaller set of candidate words based on the given context, and then conducts an exact softmax only within that subset. Training such a procedure end-to-end is challenging as traditional clustering methods are discrete and non-differentiable, and thus unable to be used with back-propagation in the training process. Using the Gumbel softmax, we are able to train the screening model end-to-end on the training set to exploit data distribution. The algorithm achieves an order of magnitude faster inference than the original softmax layer for predicting top-k words in various tasks such as beam search in machine translation or next words prediction. For example, for machine translation task on German to English dataset with around 25K vocabulary, we can achieve 20.4 times speed up with 98.9% precision@1 and 99.3% precision@5 with the original softmax layer prediction, while state-of-the-art (Zhang et al., 2018) only achieves 6.7x speedup with 98.7% precision@1 and 98.1% precision@5 for the same task.</th>\n",
       "      <th>12</th>\n",
       "      <th>233</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>5.575107296137339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pruning large neural networks while maintainin...</td>\n",
       "      <td>8</td>\n",
       "      <td>171</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>6.046784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Current end-to-end machine reading and questi...</td>\n",
       "      <td>10</td>\n",
       "      <td>158</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Neural networks make mistakes. The reason why ...</td>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4.877698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Knowledge distillation is a potential solution...</td>\n",
       "      <td>12</td>\n",
       "      <td>195</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>5.964103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Mixed-precision arithmetic combining both sing...</td>\n",
       "      <td>8</td>\n",
       "      <td>156</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1</td>\n",
       "      <td>We propose and address a novel few-shot RL pro...</td>\n",
       "      <td>9</td>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5.337838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>10</td>\n",
       "      <td>We study the problem of alleviating the instab...</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>10</td>\n",
       "      <td>Wide adoption of complex RNN based models is h...</td>\n",
       "      <td>8</td>\n",
       "      <td>119</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>6.168067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>10</td>\n",
       "      <td>Bayesian inference offers a theoretically grou...</td>\n",
       "      <td>6</td>\n",
       "      <td>183</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>6.415301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>10</td>\n",
       "      <td>The information bottleneck (IB) problem tackle...</td>\n",
       "      <td>5</td>\n",
       "      <td>203</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5.231527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     01  \\\n",
       "0     1   \n",
       "1     1   \n",
       "2    10   \n",
       "3    10   \n",
       "4    10   \n",
       "..   ..   \n",
       "490   1   \n",
       "491  10   \n",
       "492  10   \n",
       "493  10   \n",
       "494  10   \n",
       "\n",
       "    Neural language models have been widely used in various NLP tasks, including machine translation, next word prediction and conversational agents. However, it is challenging to deploy these models on mobile devices due to their slow prediction speed, where the bottleneck is to compute top candidates in the softmax layer. In this paper, we introduce a novel softmax layer approximation algorithm by exploiting the clustering structure of context vectors. Our algorithm uses a light-weight screening model to predict a much smaller set of candidate words based on the given context, and then conducts an exact softmax only within that subset. Training such a procedure end-to-end is challenging as traditional clustering methods are discrete and non-differentiable, and thus unable to be used with back-propagation in the training process. Using the Gumbel softmax, we are able to train the screening model end-to-end on the training set to exploit data distribution. The algorithm achieves an order of magnitude faster inference than the original softmax layer for predicting top-k words in various tasks such as beam search in machine translation or next words prediction. For example, for machine translation task on German to English dataset with around 25K vocabulary, we can achieve 20.4 times speed up with 98.9% precision@1 and 99.3% precision@5 with the original softmax layer prediction, while state-of-the-art (Zhang et al., 2018) only achieves 6.7x speedup with 98.7% precision@1 and 98.1% precision@5 for the same task.  \\\n",
       "0    Pruning large neural networks while maintainin...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "1     Current end-to-end machine reading and questi...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "2    Neural networks make mistakes. The reason why ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "3    Knowledge distillation is a potential solution...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "4    Mixed-precision arithmetic combining both sing...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "..                                                 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "490  We propose and address a novel few-shot RL pro...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "491  We study the problem of alleviating the instab...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "492  Wide adoption of complex RNN based models is h...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "493  Bayesian inference offers a theoretically grou...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "494  The information bottleneck (IB) problem tackle...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "\n",
       "     12  233  3  0  0.1  5.575107296137339  \n",
       "0     8  171  2  0   37           6.046784  \n",
       "1    10  158  6  0   18           5.500000  \n",
       "2    10  139  7  0   12           4.877698  \n",
       "3    12  195  5  0   22           5.964103  \n",
       "4     8  156  6  1    8           6.000000  \n",
       "..   ..  ... .. ..  ...                ...  \n",
       "490   9  148  2  0    9           5.337838  \n",
       "491   9  159  3  0   21           5.666667  \n",
       "492   8  119  7  0   21           6.168067  \n",
       "493   6  183  4  0   26           6.415301  \n",
       "494   5  203  2  1   35           5.231527  \n",
       "\n",
       "[495 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01</th>\n",
       "      <th>stochastic auc maximization has garnered an increasing interest due to better fit imbalanced data classification existing works are limited to stochastic auc maximization with a linear predictive model which restricts its predictive dealing with extremely complex data in this paper we consider stochastic auc maximization problem with a deep neural network as the predictive building on the saddle point reformulation of a surrogated loss of auc problem can be cast into a it non convex concave min max problem the main contribution in this paper is to stochastic maximization more for neural networks and big data with theoretical insights as well in particular we propose to explore polyak l ojasiewicz pl condition that has been proved and observed in deep learning which enables us to new stochastic with even faster convergence rate and more practical step size scheme an adagrad style algorithm is also analyzed under the pl condition with convergence rate results demonstrate the effectiveness of the proposed algorithms</th>\n",
       "      <th>7</th>\n",
       "      <th>160</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>29</th>\n",
       "      <th>5.43125</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The vertebrate visual system is hierarchically...</td>\n",
       "      <td>16</td>\n",
       "      <td>295</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>5.776271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>the lack of crisp mathematical models that cap...</td>\n",
       "      <td>11</td>\n",
       "      <td>163</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>5.619632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Deep neural networks with millions of paramete...</td>\n",
       "      <td>6</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6.017094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>we analyze discrete time mean field markov bet...</td>\n",
       "      <td>9</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>5.106280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>The domain of time-series forecasting has been...</td>\n",
       "      <td>6</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>5.967480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9122</th>\n",
       "      <td>10</td>\n",
       "      <td>Predicting properties of nodes in a graph is a...</td>\n",
       "      <td>7</td>\n",
       "      <td>176</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5.801136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9123</th>\n",
       "      <td>1</td>\n",
       "      <td>ego despite the widespread adoption of transfo...</td>\n",
       "      <td>7</td>\n",
       "      <td>174</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6.132184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9124</th>\n",
       "      <td>10</td>\n",
       "      <td>As deep neural net architectures minimize loss...</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>5.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9125</th>\n",
       "      <td>10</td>\n",
       "      <td>To collect large scale annotated data, it is i...</td>\n",
       "      <td>6</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5.410072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9126</th>\n",
       "      <td>10</td>\n",
       "      <td>throne recently neural network based forward d...</td>\n",
       "      <td>4</td>\n",
       "      <td>216</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>5.768519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9127 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      01  \\\n",
       "0      1   \n",
       "1     10   \n",
       "2     10   \n",
       "3      1   \n",
       "4     10   \n",
       "...   ..   \n",
       "9122  10   \n",
       "9123   1   \n",
       "9124  10   \n",
       "9125  10   \n",
       "9126  10   \n",
       "\n",
       "     stochastic auc maximization has garnered an increasing interest due to better fit imbalanced data classification existing works are limited to stochastic auc maximization with a linear predictive model which restricts its predictive dealing with extremely complex data in this paper we consider stochastic auc maximization problem with a deep neural network as the predictive building on the saddle point reformulation of a surrogated loss of auc problem can be cast into a it non convex concave min max problem the main contribution in this paper is to stochastic maximization more for neural networks and big data with theoretical insights as well in particular we propose to explore polyak l ojasiewicz pl condition that has been proved and observed in deep learning which enables us to new stochastic with even faster convergence rate and more practical step size scheme an adagrad style algorithm is also analyzed under the pl condition with convergence rate results demonstrate the effectiveness of the proposed algorithms  \\\n",
       "0     The vertebrate visual system is hierarchically...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "1     the lack of crisp mathematical models that cap...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "2     Deep neural networks with millions of paramete...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "3     we analyze discrete time mean field markov bet...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "4     The domain of time-series forecasting has been...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "...                                                 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "9122  Predicting properties of nodes in a graph is a...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "9123  ego despite the widespread adoption of transfo...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "9124  As deep neural net architectures minimize loss...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "9125  To collect large scale annotated data, it is i...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "9126  throne recently neural network based forward d...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "\n",
       "       7  160  2  1  29   5.43125  \n",
       "0     16  295  4  0  20  5.776271  \n",
       "1     11  163  5  1  23  5.619632  \n",
       "2      6  117  2  0  11  6.017094  \n",
       "3      9  207  0  0  16  5.106280  \n",
       "4      6  123  0  0  24  5.967480  \n",
       "...   ..  ... .. ..  ..       ...  \n",
       "9122   7  176  6  0  11  5.801136  \n",
       "9123   7  174  5  0  11  6.132184  \n",
       "9124  12  187  4  0  27  5.882353  \n",
       "9125   6  139  1  0   8  5.410072  \n",
       "9126   4  216  4  0  36  5.768519  \n",
       "\n",
       "[9127 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>We revisit the one-shot Neural Architecture Search (NAS) paradigm and analyze its advantages over existing NAS approaches. Existing one-shot method (Benderet al., 2018), however, is hard to train and not yet effective on large scale datasets like ImageNet.  This work propose a Single Path One-Shot model to address the challenge in the training.  Our central idea is to construct a simplified supernet, where all architectures are single paths so that weight co-adaption problem is alleviated. Training is performed by uniform path sampling. All architectures (and their weights) are trained fully and equally.Comprehensive experiments verify that our approach is flexible and effective.  It is easy to train and fast to search.  It effortlessly supports complex search spaces(e.g., building blocks, channel, mixed-precision quantization) and different search constraints (e.g., FLOPs, latency).  It is thus convenient to use for various needs. It achieves start-of-the-art performance on the large dataset ImageNet.</th>\n",
       "      <th>9</th>\n",
       "      <th>147</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>5.8979591836734695</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Probabilistic models with hierarchical-latent-...</td>\n",
       "      <td>7</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7.105691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>We propose a novel unsupervised generative mod...</td>\n",
       "      <td>8</td>\n",
       "      <td>131</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>6.137405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Crafting adversarial examples on discrete inpu...</td>\n",
       "      <td>13</td>\n",
       "      <td>201</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5.815920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Cross-lingual embeddings encode meaning of wor...</td>\n",
       "      <td>7</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Graph attention network (GAT) is a promising f...</td>\n",
       "      <td>7</td>\n",
       "      <td>211</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6.085308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>10</td>\n",
       "      <td>A long-held conventional wisdom states that la...</td>\n",
       "      <td>6</td>\n",
       "      <td>135</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6.229630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>10</td>\n",
       "      <td>Planning is important for humans when producin...</td>\n",
       "      <td>7</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>6.072368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>10</td>\n",
       "      <td>Regularization is one of the crucial ingredien...</td>\n",
       "      <td>6</td>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6.038760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>We analyze the effect of quantizing weights an...</td>\n",
       "      <td>6</td>\n",
       "      <td>149</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>6.295302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>10</td>\n",
       "      <td>A typical experiment to study cognitive functi...</td>\n",
       "      <td>10</td>\n",
       "      <td>230</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>6.156522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     10  \\\n",
       "0    10   \n",
       "1    10   \n",
       "2    10   \n",
       "3    10   \n",
       "4     1   \n",
       "..   ..   \n",
       "994  10   \n",
       "995  10   \n",
       "996  10   \n",
       "997   1   \n",
       "998  10   \n",
       "\n",
       "    We revisit the one-shot Neural Architecture Search (NAS) paradigm and analyze its advantages over existing NAS approaches. Existing one-shot method (Benderet al., 2018), however, is hard to train and not yet effective on large scale datasets like ImageNet.  This work propose a Single Path One-Shot model to address the challenge in the training.  Our central idea is to construct a simplified supernet, where all architectures are single paths so that weight co-adaption problem is alleviated. Training is performed by uniform path sampling. All architectures (and their weights) are trained fully and equally.Comprehensive experiments verify that our approach is flexible and effective.  It is easy to train and fast to search.  It effortlessly supports complex search spaces(e.g., building blocks, channel, mixed-precision quantization) and different search constraints (e.g., FLOPs, latency).  It is thus convenient to use for various needs. It achieves start-of-the-art performance on the large dataset ImageNet.  \\\n",
       "0    Probabilistic models with hierarchical-latent-...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "1    We propose a novel unsupervised generative mod...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "2    Crafting adversarial examples on discrete inpu...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "3    Cross-lingual embeddings encode meaning of wor...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "4    Graph attention network (GAT) is a promising f...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "..                                                 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "994  A long-held conventional wisdom states that la...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "995  Planning is important for humans when producin...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "996  Regularization is one of the crucial ingredien...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "997  We analyze the effect of quantizing weights an...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "998  A typical experiment to study cognitive functi...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "\n",
       "      9  147  2  0  0.1  5.8979591836734695  \n",
       "0     7  123  2  0    9            7.105691  \n",
       "1     8  131  3  0   17            6.137405  \n",
       "2    13  201  5  0   15            5.815920  \n",
       "3     7  128  4  0    0            5.890625  \n",
       "4     7  211  3  1   11            6.085308  \n",
       "..   ..  ... .. ..  ...                 ...  \n",
       "994   6  135  5  0   18            6.229630  \n",
       "995   7  152  4  0   12            6.072368  \n",
       "996   6  129  9  0   11            6.038760  \n",
       "997   6  149  4  0   16            6.295302  \n",
       "998  10  230  4  0   17            6.156522  \n",
       "\n",
       "[999 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.concatenate([df1['12'], df2['7'], df3['9'], [12, 7, 9]])\n",
    "x2 = np.concatenate([df1['233'], df2['160'], df3['147'], [233, 160, 147]])\n",
    "x3 = np.concatenate([df1['3'], df2['2'], df3['2'], [3, 2, 2]])\n",
    "x4 = np.concatenate([df1['0'], df2['1'], df3['0'], [0, 1, 0]])\n",
    "x5 = np.concatenate([df1['0.1'], df2['29'], df3['0.1'], [0.1, 29, 0.1]])\n",
    "x6 = np.concatenate([df1['5.575107296137339'], df2['5.43125'], df3['5.8979591836734695']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x1_mean = x1.mean()\n",
    "x1_std = x1.std()\n",
    "x2_mean = x2.mean()\n",
    "x2_std = x2.std()\n",
    "x3_mean = x3.mean()\n",
    "x3_std = x3.std()\n",
    "x4_mean = x4.mean()\n",
    "x4_std = x4.std()\n",
    "x5_mean = x5.mean()\n",
    "x5_std = x5.std()\n",
    "x6_mean = x6.mean()\n",
    "x6_std = x6.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.822665662650603, 2.7551960445021373)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_mean, x1_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166.06381777108433, 47.26115315428536)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_mean, x2_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.5775602409638556, 1.9726597571439843)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3_mean, x3_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2001129518072289, 1.4225936094343088)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4_mean, x4_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.85120481927711, 10.327860523418273)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x5_mean, x5_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.767814719152102, 0.391475719260566)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x6_mean, x6_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
